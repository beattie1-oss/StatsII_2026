req_method("GET") %>%
req_headers(
"Accept" = "application/JSON, text/JSON",
) %>%
req_url_query(page = 1, limit = 50) %>%
req_perform()
#### Set up ####
libs <- c("tidyverse",
"rvest",
"polite",
"httr2",
"stringr",
"lubridate",
"jsonlite", "xml2")
install.packages(setdiff(libs, rownames(installed.packages())))
lapply(libs, library, character.only = TRUE)
url <- "https://api.oireachtas.ie/v1/debates?chamber_type=house&chamber=dail&date_start=2025-01-01&date_end=2025-02-28&skip=0&limit=50"
####Build Request ####
#Build request
response <- request(url) %>%
req_method("GET") %>%
req_headers(
"Accept" = "application/JSON, text/JSON",
) %>%
req_url_query(page = 1, limit = 50) %>%
req_perform()
#Parse JSON repsonse
json <- response %>% resp_body_json()
results <- json$results
names(results) <- seq_along(results)
#Collect the urls to read info
xml_urls = c()
xml_urls <- lapply(results[1:13], function(s) s[["debateRecord"]][["formats"]][["xml"]][["uri"]])
# Create a collection of the xml documents
xml_docs <- lapply(xml_urls, read_xml)
all_speeches <- lapply(xml_docs, function(doc) {
speech_nodes <- xml_find_all(doc, ".//*[local-name()='speech']")
lapply(speech_nodes, function(s) {
paras <- xml_find_all(s, ".//*[local-name()='p']")
data.frame(
speech_id = xml_attr(s, "eId"),
speaker   = xml_text(xml_find_first(s, ".//*[local-name()='from']"), trim = TRUE),
time      = xml_attr(xml_find_first(s, ".//*[local-name()='recordedTime']"), "time"),
para_id   = xml_attr(paras, "eId"),
text      = xml_text(paras, trim = TRUE),
stringsAsFactors = FALSE
)
}) |> bind_rows()
}) |> bind_rows(.id = "doc_id")
View(all_speeches)
View(all_speeches)
# Function to extract a single speech
extract_speech <- function(speech_node, doc_id = NA_character_) {
# Get all <p> nodes inside this speech
paras <- xml_find_all(speech_node, ".//*[local-name()='p']")
text_combined <- paste(xml_text(paras, trim = TRUE), collapse = "\n\n")
# Extract metadata
speaker <- xml_text(xml_find_first(speech_node, ".//*[local-name()='from']"), trim = TRUE)
time_str <- xml_attr(xml_find_first(speech_node, ".//*[local-name()='recordedTime']"), "time")
# Parse time directly
time_parsed <- if (!is.na(time_str) && nchar(time_str) > 0) ymd_hms(time_str, tz = "UTC") else NA
# Return a single-row data frame
data.frame(
doc_id    = doc_id,
speech_id = xml_attr(speech_node, "eId"),
speaker   = speaker,
time      = time_parsed,
text      = text_combined,
stringsAsFactors = FALSE
)
}
# Function to extract all speeches from a single document
extract_doc_speeches <- function(doc, doc_id = NA_character_) {
speech_nodes <- xml_find_all(doc, ".//*[local-name()='speech']")
lapply(speech_nodes, extract_speech, doc_id = doc_id) %>% bind_rows()
}
# Loop over all XML documents
all_speeches2 <- lapply(seq_along(xml_docs), function(i) {
extract_doc_speeches(xml_docs[[i]], doc_id = i)
}) %>% bind_rows()
View(all_speeches2)
# Function to extract a single speech
extract_speech <- function(speech_node, doc_id = NA_character_) {
# Get all <p> nodes inside this speech
paras <- xml_find_all(speech_node, ".//*[local-name()='p']")
text_combined <- paste(xml_text(paras, trim = TRUE), collapse = "\n\n")
# Speaker name
by_attr <- xml_attr(speech_node, "by")
speaker <- if (!is.na(by_attr)) sub ("^#", "", by_attr) else NA
# Date
time_str <- xml_attr(xml_find_first(speech_node, ".//*[local-name()='recordedTime']"), "time")
date <- if (!is.na(time_str) && nchar(time_str) > 0) substr(time_str,1,10) else NA
# Parse time directly
time_parsed <- if (!is.na(time_str) && nchar(time_str) > 0) ymd_hms(time_str, tz = "UTC") else NA
# Return a single-row data frame
data.frame(
doc_id    = doc_id,
speech_id = xml_attr(speech_node, "eId"),
speaker   = speaker,
time      = time_parsed,
text      = text_combined,
stringsAsFactors = FALSE
)
}
# Function to extract a single speech
extract_speech <- function(speech_node, doc_id = NA_character_) {
# Dail
# Vol
# No
# Get all <p> nodes inside this speech
paras <- xml_find_all(speech_node, ".//*[local-name()='p']")
text_combined <- paste(xml_text(paras, trim = TRUE), collapse = "\n\n")
# Speaker name
by_attr <- xml_attr(speech_node, "by")
speaker <- if (!is.na(by_attr)) sub ("^#", "", by_attr) else NA
# Date
time_str <- xml_attr(xml_find_first(speech_node, ".//*[local-name()='recordedTime']"), "time")
date <- if (!is.na(time_str) && nchar(time_str) > 0) substr(time_str,1,10) else NA
# Parse time directly
time_parsed <- if (!is.na(time_str) && nchar(time_str) > 0) ymd_hms(time_str, tz = "UTC") else NA
# Return a single-row data frame
data.frame(
doc_id    = doc_id,
speech_id = xml_attr(speech_node, "eId"),
speaker   = speaker,
time      = time_parsed,
text      = text_combined,
stringsAsFactors = FALSE
)
}
# Function to extract all speeches from a single document
extract_doc_speeches <- function(doc, doc_id = NA_character_) {
speech_nodes <- xml_find_all(doc, ".//*[local-name()='speech']")
lapply(speech_nodes, extract_speech, doc_id = doc_id) %>% bind_rows()
}
# Loop over all XML documents
all_speeches2 <- lapply(seq_along(xml_docs), function(i) {
extract_doc_speeches(xml_docs[[i]], doc_id = i)
}) %>% bind_rows()
View(xml_docs)
View(response)
View(json)
##################
#### Stats II ####
##################
###############################
#### Tutorial 3: MLE ####
###############################
# In today's tutorial, we'll begin to explore MLE in R
#     1. Import/wrangle data
#     2. Create log-likelihood functions
#     3. Compare our own MLE models with build-in function glm()
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
##################
#### Stats II ####
##################
###############################
#### Tutorial 3: MLE ####
###############################
# In today's tutorial, we'll begin to explore MLE in R
#     1. Import/wrangle data
#     2. Create log-likelihood functions
#     3. Compare our own MLE models with build-in function glm()
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# set seed so we all get same answers
set.seed(1234)
# create design matrix
# only 2 predictors, remember 1st column is 1s
X <- rnorm(100)
# define "real"/true relationship
real_beta <- 3
# create output variables
# as linear function of covariates
# (1) binom
y_binom <- rbinom(100, 1, exp(X*real_beta)/(1+exp(X*real_beta)))
# derive our log-likelihood function for binomial distribution
binom_likelihood <- function(outcome, input, parameter) {
# calculate probability of success on each trial
p <- exp(parameter[1] + parameter[2]*input)/(1+exp(parameter[1] + parameter[2]*input))
# access probability density function (pdf) for binomial distribution
# specifically, calculate log.likelihood function
# using sum and negative since its' log, not normal likelihood function
-sum(dbinom(outcome, 1, p, log=TRUE))
}
# optimise our log-likelihood function
# need to put in par, which are initial values for parameters to be optimized over
# we'll start with zero and 1 for intercept and beta
# using BFGS because it's a quasi-Newton method
# so similar to what we did in class, and what you'll get from glm()
results_binom <- optim(fn=binom_likelihood, outcome=y_binom, input=X, par=0:1, hessian=T, method="BFGS")
# print our estimated coefficients (intercept and beta_1)
results_binom$par
# confirm that we get the same thing in with glm()
coef(glm(y_binom~X, family=binomial))
# now do the same process to derive our log-likelihood function for normal distribution
# we can use the same predictor and "real" effect, just need to create a new outcome variable
y_norm <- X*real_beta + rnorm(100, 0, 0.5)
norm_likelihood <- function(outcome, input, parameter) {
n      <- nrow(input)
k      <- ncol(input)
beta   <- parameter[1:k]
sigma2 <- parameter[k+1]^2
e      <- outcome - input%*%beta
logl   <- -.5*n*log(2*pi)-.5*n*log(sigma2) - ( (t(e) %*% e)/ (2*sigma2) )
return(-logl)
}
# show you two different ways to set up same likelihood function
norm_likelihood2 <- function(outcome, input, parameter) {
n <- ncol(input)
beta <- parameter[1:n]
sigma <- sqrt(parameter[1+n])
-sum(dnorm(outcome, input %*% beta, sigma, log=TRUE))
}
# print our estimated coefficients (intercept and beta_1)
results_norm <- optim(fn=norm_likelihood, outcome=y_norm, input=cbind(1, X), par=c(1,1,1), hessian=T, method="BFGS")
results_norm2 <- optim(fn=norm_likelihood, outcome=y_norm, input=cbind(1, X), par=c(1,1,1), hessian=T, method="BFGS")
# print our estimated coefficients (intercept and beta_1)
# get same results regardless of which log-likelihood function we use
results_norm$par; results_norm2$par
# Q: what that third parameter that we've exstimated w/ our log-likelihood function?
# confirm that we get the same thing in with glm()
coef(lm(y_norm~X))
# now your turn using the poisson distribution:
# first, let's create design matrix w/ only 1 predictor
X <- rnorm(100)
# define "real"/true relationship
real_beta0 <- 0.5      # true intercept
real_beta1 <- 0.8      # true slope
# create output variable
# as a log-linear function of covariates
# log(lambda_i) = beta0 + beta1 * X_i
lambda <- exp(real_beta0 + real_beta1 * X)
y_pois <- rpois(100, lambda)
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
# set seed so we all get same answers
set.seed(1234)
# set seed so we all get same answers
set.seed(1234)
# create design matrix
# only 2 predictors, remember 1st column is 1s
X <- rnorm(100)
# Createderive our log-likelihood function for binomial distribution
binom_likelihood <- function(outcome, input, parameter) {
# calculate probability of success on each trial
p <- exp(parameter[1] + parameter[2]*input)/(1+exp(parameter[1] + parameter[2]*input))
# access probability density function (pdf) for binomial distribution
# specifically, calculate log.likelihood function
# using sum and negative since its' log, not normal likelihood function
-sum(dbinom(outcome, 1, p, log=TRUE))
}
# optimise our log-likelihood function
# need to put in par, which are initial values for parameters to be optimized over
# we'll start with zero and 1 for intercept and beta
# using BFGS because it's a quasi-Newton method
# so similar to what we did in class, and what you'll get from glm()
results_binom <- optim(fn=binom_likelihood, outcome=y_binom, input=X, par=0:1, hessian=T, method="BFGS")
# print our estimated coefficients (intercept and beta_1)
results_binom$par
gc()
# print our estimated coefficients (intercept and beta_1)
results_binom$par
# confirm that we get the same thing in with glm()
coef(glm(y_binom~X, family=binomial))
#Likelihood function for a normal distribution
norm_likelihood <- function(outcome, input, parameter) {
n      <- nrow(input)
k      <- ncol(input)
beta   <- parameter[1:k]
sigma2 <- parameter[k+1]^2
e      <- outcome - input%*%beta
logl   <- -.5*n*log(2*pi)-.5*n*log(sigma2) - ( (t(e) %*% e)/ (2*sigma2) )
return(-logl)
}
# show you two different ways to set up same likelihood function
norm_likelihood2 <- function(outcome, input, parameter) {
n <- ncol(input)
beta <- parameter[1:n]
sigma <- sqrt(parameter[1+n])
-sum(dnorm(outcome, input %*% beta, sigma, log=TRUE))
}
View(norm_likelihood)
results_norm2 <- optim(fn=norm_likelihood, outcome=y_norm, input=cbind(1, X), par=c(1,1,1), hessian=T, method="BFGS")
# Q: what that third parameter that we've exstimated w/ our log-likelihood function?
# confirm that we get the same thing in with glm()
coef(lm(y_norm~X))
#Built in GLM function
coef(lm(y_norm~X))
# Poisson Function
# now your turn using the poisson distribution:
# first, let's create design matrix w/ only 1 predictor
X <- rnorm(100)
# define "real"/true relationship
real_beta0 <- 0.5      # true intercept
real_beta1 <- 0.8      # true slope
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
poisson_likelihood <- function(outcome, input, parameter) {
# define "real"/true relationship
lambda <- exp(real_beta0 + real_beta1 * X)
sum(dpois(input,lambda, log = FALSE))
}
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=cbind(1, X), par=c(1,1,1), hessian=T, method="BFGS")
warnings()
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
poisson_likelihood <- function(outcome, input, parameter) {
# define "real"/true relationship
lambda <- exp(real_beta0 + real_beta1 * X)
sum(dpois(input,lambda, log = TRUE))
}
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=cbind(1, X), par=c(1,1,1), hessian=T, method="BFGS")
warnings()
sum(dpois(input, lambda = lambda, log = TRUE))
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
poisson_likelihood <- function(outcome, input, parameter) {
# define "real"/true relationship
lambda <- exp(real_beta0 + real_beta1 * X)
sum(dpois(input, lambda = lambda, log = TRUE))
}
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=cbind(1, X), par=c(1,1,1), hessian=T, method="BFGS")
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
poisson_likelihood <- function(outcome, input, parameter) {
# define "real"/true relationship
lambda <- exp(real_beta0 + real_beta1 * X)
-sum(dpois(input, lambda = lambda, log = TRUE))
}
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=cbind(1, X), par=c(1,1,1), hessian=T, method="BFGS")
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
poisson_likelihood <- function(outcome, input, parameter) {
# define "real"/true relationship
lambda <- exp(parameter[1] + parameter[2] * input)
-sum(dpois(input, lambda = lambda, log = TRUE))
}
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=cbind(1, X), par=c(1,1,1), hessian=T, method="BFGS")
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
poisson_likelihood <- function(outcome, input, parameter) {
# define "real"/true relationship
lambda <- exp(parameter[1] + parameter[2] * input)
-sum(dpois(input, lambda = lambda, log = TRUE))
}
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
poisson_likelihood <- function(outcome, input, parameter) {
# define "real"/true relationship
lambda <- exp(parameter[1] + parameter[2] * input)
-sum(dpois(input, lambda, log = TRUE))
}
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=X, par=c(0,1), hessian=T, method="BFGS")
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
poisson_likelihood <- function(outcome, input, parameter) {
# define "real"/true relationship
lambda <- exp(parameter[1] + parameter[2] * input)
-sum(dpois(input, lambda, log = TRUE))
}
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=X, par=c(0,1), hessian=T, method="BFGS")
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=X, par=c(0,1), hessian=T, method="BFGS")
warnings()
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=X, par=0:1, hessian=T, method="BFGS")
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=X, par=c(0:1), hessian=T, method="BFGS")
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=X, par=c(0,1), hessian=T, method="BFGS")
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
poisson_likelihood <- function(outcome, input, parameter) {
# define "real"/true relationship
lambda <- exp(parameter[1] + parameter[2] * input)
-sum(dpois(outcome, lambda, log = TRUE))
}
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=X, par=c(0,1), hessian=T, method="BFGS")
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=X, par=c(0,1), hessian=T, method="BFGS")
results_poisson$cor
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=X, par=c(0,1), hessian=T, method="BFGS")
results_poisson$corr
results_poisson$pr
results_poisson$par
coef(glm(y_pois~X, family=poisson))
y_pois <- rpois(100, lambda)
# Poisson Function
# now your turn using the poisson distribution:
# first, let's create design matrix w/ only 1 predictor
X <- rnorm(100)
# define "real"/true relationship
real_beta0 <- 0.5      # true intercept
real_beta1 <- 0.8      # true slope
# create output variable
# as a log-linear function of covariates
# log(lambda_i) = beta0 + beta1 * X_i
lambda <- exp(real_beta0 + real_beta1 * X)
y_pois <- rpois(100, lambda)
# write your own likelihood function
# maximize your likelihood function using optim(), print the results
# compare your results to the built-in glm() function
poisson_likelihood <- function(outcome, input, parameter) {
# define "real"/true relationship
lambda <- exp(parameter[1] + parameter[2] * input)
-sum(dpois(outcome, lambda, log = TRUE))
}
results_poisson <- optim(fn=poisson_likelihood, outcome=y_pois, input=X, par=c(0,1), hessian=T, method="BFGS")
results_poisson$par
coef(glm(y_pois~X, family=poisson))
data <- data.frame(x = runif(200, 1, 10))
View(data)
plot(data$x)
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
plot(data$x,data$y)
plot(data$y)
plot(data$y)
density(data$y)
library(ggplot2)
ggplot(data = data, aes(x = data$x, data$y)) +
gg
library(ggplot2)
ggplot(data = data, aes(x = data$x, data$y)) +
gg
ggplot(data, aes(x = data$x, data$y)) +
gg
library(ggplot2)
ggplot(data, aes(x = data$x, data$y)) +
gg
ggplot(data, aes(y)) +
geom_density(y)
ggplot(data, aes(y)) +
geom_density(data$y)
ggplot(data, aes(y = data$y)) +
geom_density(data$y)
ggplot(data, aes(y = data$y)) +
geom_density()
ggplot(data, aes(x = data$y)) +
geom_density()
coef(lm(data$y~data$x))
linear_lik <- function(outcome, input, theta) {
n      <- nrow(input)
k      <- ncol(input)
beta   <- theta[1:k]
sigma2 <- theta[k+1]^2
e      <- outcome - input%*%beta
logl   <- -.5*n*log(2*pi)-.5*n*log(sigma2) - ( (t(e) %*% e)/ (2*sigma2) )
return(-logl)
}
linear_lik <- function(y, X, theta) {
n      <- nrow(X)
k      <- ncol(X)
beta   <- theta[1:k]
sigma2 <- theta[k+1]^2
e      <- y - X%*%beta
logl   <- -.5*n*log(2*pi)-.5*n*log(sigma2) - ( (t(e) %*% e)/ (2*sigma2) )
return(-logl)
}
linear_MLE <- optim(fn=linear_lik, y =data$y, X =cbind(1, X), par=c(1,1,1), hessian=TRUE, method="BFGS")
set.seed (123)
data <- data.frame(x = runif(200, 1, 10))
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
set.seed (123)
data <- data.frame(x = runif(200, 1, 10))
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
linear_MLE <- optim(fn=linear_lik, y =data$y, X =cbind(1, data$x), par=c(1,1,1), hessian=TRUE, method="BFGS")
linear_MLE$par
coef(lm(data$y~data$x))
summary(lm(data$y~data$x))
sigma(lm(data$y~data$x))
sigma^2(lm(data$y~data$x))
